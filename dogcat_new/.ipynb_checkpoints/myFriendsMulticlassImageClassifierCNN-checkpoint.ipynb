{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Kishan\\Anaconda3\\envs\\dogcat_test\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Kishan\\Anaconda3\\envs\\dogcat_test\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Kishan\\Anaconda3\\envs\\dogcat_test\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Kishan\\Anaconda3\\envs\\dogcat_test\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Kishan\\Anaconda3\\envs\\dogcat_test\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Kishan\\Anaconda3\\envs\\dogcat_test\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#importing the librariers to create the model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a pipleline sequential\n",
    "\n",
    "image_classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a convolution layer and setting the kernels\n",
    "\n",
    "image_classifier.add(Convolution2D(32,(3,3),input_shape=(64,64,3),activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Kishan\\Anaconda3\\envs\\dogcat_test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#creating a pooling layers\n",
    "image_classifier.add(MaxPooling2D(pool_size=(3,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flattening the convoluted data\n",
    "\n",
    "image_classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding neural network\n",
    "\n",
    "image_classifier.add(Dense(units=64,activation='softmax'))\n",
    "image_classifier.add(Dense(units=3,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compling the CNN\n",
    "image_classifier.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#tf.keras.losses.categorical_crossentropy\n",
    "#tf.keras.optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting tghe CNN to images\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen= ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.losses.categorical_crossentropy\n",
    "#tf.keras.optimizers. This is how you can check the loss and optimizer and activation function available iwth name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 33 images belonging to 3 classes.\n",
      "Found 33 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "#creating the dataset\n",
    "training_set= train_datagen.flow_from_directory(r'F:\\images_CNN',target_size=(64,64),batch_size=32,class_mode='categorical')\n",
    "test_set= test_datagen.flow_from_directory(r'F:\\images_CNN',target_size=(64,64),batch_size=32,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kishan\\Anaconda3\\envs\\dogcat_test\\lib\\site-packages\\keras\\utils\\data_utils.py:616: UserWarning: The input 0 could not be retrieved. It could be because a worker has died.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262/800 [========>.....................] - ETA: 1:59:02 - loss: 0.0592 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "image_classify_model= image_classifier.fit_generator(training_set,steps_per_epoch=800,epochs=2,validation_data=test_set,validation_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "image_classifier.save(\"image_classify_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Baby': 0, 'Kishan': 1, 'Rakesh': 2}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': 2,\n",
       " 'steps': 800,\n",
       " 'verbose': 1,\n",
       " 'do_validation': True,\n",
       " 'metrics': ['loss', 'accuracy', 'val_loss', 'val_accuracy']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_classify_model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "its Rakesh\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "test_image= image.load_img(r'F:\\Gujrat trop\\IMG_20190219_112645.jpg',target_size=(64,64))\n",
    "test_image= image.img_to_array(test_image)\n",
    "test_image=np.expand_dims(test_image,axis=0)\n",
    "model=load_model(\"image_classify_model.h5\")\n",
    "result=model.predict_proba(test_image)\n",
    "if np.argmax(result[0]) == 0:\n",
    "    print(\"its baby\")\n",
    "elif np.argmax(result[0]) == 1:\n",
    "    print(\"Its Kishan\")\n",
    "else:\n",
    "    print(\"its Rakesh\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "nn=np.load(r'C:/Users/Kishan/Downloads/conv2d_1_kernel_0 (1).npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.12050168,  0.03848144, -0.11384341, -0.08852763, -0.00787206,\n",
       "         0.15771195, -0.01851995, -0.09459576,  0.09650394,  0.12857354,\n",
       "        -0.02361998, -0.07557377, -0.01236992,  0.025731  , -0.10494816,\n",
       "        -0.05806601, -0.050201  , -0.10117855, -0.13493995,  0.06230396,\n",
       "        -0.05232795, -0.02253981,  0.04285239,  0.10415566, -0.18098663,\n",
       "         0.06549856, -0.05211704, -0.10665832, -0.1207348 , -0.09216708,\n",
       "         0.10079101, -0.02211122],\n",
       "       [ 0.0377595 , -0.09808479,  0.06306689, -0.036848  ,  0.01040586,\n",
       "         0.10216539, -0.08481596,  0.13378517,  0.03966426,  0.0148929 ,\n",
       "        -0.12681775,  0.11465637, -0.06648129, -0.04459801,  0.11473614,\n",
       "         0.01414053,  0.05510355, -0.12543698, -0.1297576 , -0.07653151,\n",
       "        -0.03219608, -0.07224974, -0.08421243,  0.01752902, -0.15432309,\n",
       "        -0.0294784 ,  0.03504584,  0.1031573 ,  0.09856116,  0.12516576,\n",
       "        -0.13113822, -0.09152312],\n",
       "       [-0.02174964, -0.10228779, -0.10854736,  0.12584217, -0.11603716,\n",
       "        -0.07188134,  0.09785535, -0.06266864,  0.089081  , -0.02683245,\n",
       "         0.10259806, -0.02749385,  0.13289303, -0.02601698, -0.10573851,\n",
       "        -0.03635626, -0.04999159, -0.03542865,  0.1292808 ,  0.08803789,\n",
       "        -0.0482326 ,  0.02555752,  0.09119938, -0.00568882,  0.0078059 ,\n",
       "         0.0251876 , -0.0673709 , -0.12251863,  0.16082524,  0.13685247,\n",
       "        -0.00193102,  0.00656079]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f9d9d767f0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(nn[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
